{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqtm6YMB9S_H"
      },
      "source": [
        "# Google Colab y Python - Introducción al Machine Learning\n",
        "Este notebook está diseñado para que aprendas los conceptos básicos necesarios\n",
        "para el procesamiento de datos en proyectos de machine learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5oYeSr19S_I"
      },
      "source": [
        "## 1. Sintaxis básica de Python\n",
        "En esta celda, aprenderemos los fundamentos de Python:\n",
        "- Cómo imprimir texto en la pantalla\n",
        "- Cómo crear variables y asignarles valores\n",
        "- Diferentes tipos de datos: números enteros, decimales y texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2UDud-J9S_J",
        "outputId": "fccaaa44-db98-43dd-d0a3-b30e6f7da761"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "¡Hola, Colab!\n",
            "el valor de X es: 3.14\n"
          ]
        }
      ],
      "source": [
        "# 1. Sintaxis básico\n",
        "print(\"¡Hola, Colab!\")\n",
        "x = 10\n",
        "y = 3.14\n",
        "nombre = \"Juan\"\n",
        "print(\"el valor de X es: \"+ str(y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV9zWb-y9S_J"
      },
      "source": [
        "## 2. Tipos de datos en Python\n",
        "Aquí veremos cómo identificar el tipo de datos de una variable:\n",
        "- Usamos la función `type()` para conocer el tipo de dato\n",
        "- Veremos tipos como `int` (entero), `float` (decimal) y `str` (texto)\n",
        "\n",
        "**Resumen**:\n",
        "- Escalares: Valores individuales, utilizados para representar características o medidas simples.\n",
        "- Listas: Colecciones de datos, flexibles y modificables, útiles para almacenar series de datos.\n",
        "- Tuplas: Colecciones de datos inmutables, usadas para datos constantes.\n",
        "- Vectores: Estructuras unidimensionales que representan características o puntos en el espacio.\n",
        "- Matrices: Tablas bidimensionales, esenciales para cálculos matriciales.\n",
        "- Tensores: Extensiones de matrices a múltiples dimensiones, útiles en machine learning.\n",
        "- DataFrames: Tablas etiquetadas, el formato más utilizado para el análisis de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHypW4iC9S_K",
        "outputId": "db30f94e-b273-4bfd-9e87-97a44ca137f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'int'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n"
          ]
        }
      ],
      "source": [
        "# 2. Tipos de datos\n",
        "print(type(x))\n",
        "print(type(y))\n",
        "print(type(nombre))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6bU8-EgPcrN"
      },
      "source": [
        "### 2. 1 Estructuras de Datos en Python para Data Science\n",
        "Esta lección cubre la creación y uso de las estructuras de datos más comunes en Python que son fundamentales para el análisis y procesamiento de datos en ciencia de datos: escalares, listas, tuplas, vectores, matrices y dataframes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJuwgoimPq2H"
      },
      "source": [
        "## 2.1.1. Escalares\n",
        "Un escalar es una variable que almacena un solo valor. En Data Science, los escalares pueden representar características individuales como el precio de un producto o el valor de una medida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwaZfeRFPo91",
        "outputId": "24495c13-4f81-411e-b663-65615dd8f9dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Escalar: 5\n"
          ]
        }
      ],
      "source": [
        "# Ejemplo de un escalar\n",
        "escalar = 5\n",
        "print(\"Escalar:\", escalar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNF6L2e-Pyyy"
      },
      "source": [
        "##2.1.2. Listas\n",
        "Las listas en Python son colecciones ordenadas de elementos. Se usan en Data Science para almacenar conjuntos de datos simples o series de valores.\n",
        "\n",
        "**Aplicación en Data Science:** Las listas se utilizan para almacenar muestras de datos o características individuales de un conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxVR-2yjPx3Z",
        "outputId": "838ceb9f-7308-40d9-bb6e-5ccb9272e6fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lista: [1, 2, 3, 4, 5]\n",
            "Lista Modificada: [1, 2, 6, 4, 5]\n",
            "Primer elemento: 5\n"
          ]
        }
      ],
      "source": [
        "# Ejemplo de una lista\n",
        "lista = [1, 2, 3, 4, 5]\n",
        "print(\"Lista:\", lista)\n",
        "lista[2]=\"Seis\"\n",
        "lista[2]=6\n",
        "print(\"Lista Modificada:\", lista)\n",
        "# Acceder a un elemento de la lista\n",
        "print(\"Primer elemento:\", lista[4])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HwwsnbWQN-i"
      },
      "source": [
        "##2.1.3. Tuplas\n",
        "Las tuplas son similares a las listas, pero son inmutables, es decir, no se pueden modificar una vez creadas. En Data Science, se utilizan para almacenar datos que no deben cambiar, como coordenadas o parámetros de un modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zT5eiap8QJfb",
        "outputId": "2fd05f4c-3797-4e35-9390-7d498df3da9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tupla: (1, 2, 3)\n",
            "Segundo elemento de la tupla: 2\n"
          ]
        }
      ],
      "source": [
        "# Ejemplo de una tupla\n",
        "tupla = (1, 2, 3)\n",
        "print(\"Tupla:\", tupla)\n",
        "\n",
        "# Acceder a un elemento de la tupla\n",
        "print(\"Segundo elemento de la tupla:\", tupla[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qp1O2vJ0QUhG"
      },
      "source": [
        "##2.1.4. Vectores\n",
        "Un vector es una estructura de datos que contiene una secuencia de números. En Data Science, los vectores se usan para representar características de un conjunto de datos o puntos en el espacio.\n",
        "\n",
        "Vamos a crear un vector usando NumPy, una librería muy popular en Data Science."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y52fiZRTQZp3",
        "outputId": "86d45422-e4e1-4c53-e782-1534703a11a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector: [1 2 3 4 5]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Ejemplo de un vector (array de una dimensión)\n",
        "vector = np.array([1, 2, 3, 4, 5])\n",
        "print(\"Vector:\", vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jxoxoih-Qcxi"
      },
      "source": [
        "##2.1.5. Matrices\n",
        "Una matriz es una estructura bidimensional, es decir, contiene filas y columnas. En Data Science, las matrices se utilizan para representar conjuntos de datos tabulares o transformaciones matemáticas.\n",
        "\n",
        "**Aplicación en Data Science**: Las matrices son esenciales para cálculos matriciales en machine learning y álgebra lineal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUR2ggktQlKf",
        "outputId": "29b0a352-12c7-414a-ab53-0d4c9af63950"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matriz:\n",
            " [[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]]\n"
          ]
        }
      ],
      "source": [
        "# Ejemplo de una matriz (array de dos dimensiones)\n",
        "matriz = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "print(\"Matriz:\\n\", matriz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCi9hydtQtBX"
      },
      "source": [
        "##2.1.6. Matrices de diferentes dimensiones\n",
        "Además de matrices 2D, puedes trabajar con matrices de más dimensiones, llamadas tensores.\n",
        "\n",
        "**Aplicación en Data Science**: Los tensores son comunes en redes neuronales y otras aplicaciones de machine learning de alta dimensión.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwCj2F5PQ1p3",
        "outputId": "a67a38b0-fe06-4ff2-bdc5-37391ef7e821"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matriz 3D (Tensor):\n",
            " [[[1 2]\n",
            "  [3 4]]\n",
            "\n",
            " [[5 6]\n",
            "  [7 8]]]\n"
          ]
        }
      ],
      "source": [
        "# Ejemplo de una matriz 3D (tensor)\n",
        "tensor = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
        "print(\"Matriz 3D (Tensor):\\n\", tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BluYAIhOQ5jt"
      },
      "source": [
        "##2.1.7. DataFrames\n",
        "Un DataFrame es una estructura de datos similar a una tabla en pandas, con etiquetas para las filas y columnas. Es el formato más utilizado para manipular y analizar datos en Data Science.\n",
        "\n",
        "**Aplicación en Data Science**: Los DataFrames permiten la manipulación eficiente de datos tabulares, como limpieza de datos, transformación y análisis estadístico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD4VsBYfRlef",
        "outputId": "d85ebab8-9817-4a06-d371-870650b8f63f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame:\n",
            "   Nombre  Edad     Ciudad\n",
            "0    Ana    23     Madrid\n",
            "1   Luis    30  Barcelona\n",
            "2  Pedro    25    Sevilla\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Crear un DataFrame simple\n",
        "datos = {'Nombre': ['Ana', 'Luis', 'Pedro'],\n",
        "         'Edad': [23, 30, 25],\n",
        "         'Ciudad': ['Madrid', 'Barcelona', 'Sevilla']}\n",
        "\n",
        "df = pd.DataFrame(datos)\n",
        "print(\"DataFrame:\\n\", df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz0cAoCx9S_K"
      },
      "source": [
        "## 3. Navegación de Datos en DataFrames\n",
        "En esta sección, aprenderemos a manejar DataFrames, una de las estructuras más importantes para trabajar con datos en ciencia de datos. Veremos cómo crear DataFrames a partir de diferentes fuentes de datos (Excel, JSON, TXT, SQL), cómo acceder a elementos específicos dentro de ellos, y cómo extraer secciones para crear listas y diccionarios.\n",
        "\n",
        "En esta lección, aprenderemos:\n",
        "\n",
        "- Cómo crear DataFrames a partir de distintas fuentes de datos.\n",
        "- Cómo acceder a elementos específicos dentro de un DataFrame.\n",
        "- Cómo extraer secciones de un DataFrame para crear listas y diccionarios.\n",
        "\n",
        "¡Sigue practicando con tus propios datasets para dominar la manipulación de datos con DataFrames!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hDwPzTI_nIo",
        "outputId": "20036e5d-9455-43ed-94f3-ffbad30244da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yttWNDjxbqqp"
      },
      "source": [
        "##3.1. Crear un DataFrame a partir de diferentes fuentes de datos\n",
        "Los DataFrames pueden crearse a partir de diversas fuentes de datos, como archivos de Excel, JSON, TXT y bases de datos SQL. Usaremos la librería pandas para ello.\n",
        "\n",
        "**Aplicación en Data Science**: Los DataFrames nos permiten importar y manipular grandes cantidades de datos desde diferentes formatos para analizarlos de manera eficiente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        },
        "id": "9-kdPgCWbucl",
        "outputId": "26fc276c-3db8-4f3c-f958-9e02373b1275"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     AÑO         COL        EA19   EU27_2020         KOR         MEX  \\\n",
            "0   2005   92.166092  145.516381  138.769636   70.494390  113.390317   \n",
            "1   2006   98.096402  147.592492  141.078690   73.429329  115.600117   \n",
            "2   2007  102.210352  148.946321  142.418323   78.075747  116.942833   \n",
            "3   2008  102.328402  148.642103  142.064119   82.473976  116.237698   \n",
            "4   2009   99.655900  147.033243  140.426377   85.326469  109.327697   \n",
            "5   2010  100.118519  150.670174  144.499922   90.409766  113.237347   \n",
            "6   2011  103.559709  152.936951  147.141967  125.876870  115.242915   \n",
            "7   2012  104.751943  153.846029  147.951763  127.704986  116.170932   \n",
            "8   2013  108.567259  155.268120  149.233188  130.754201  116.132398   \n",
            "9   2014  111.435028  156.417419  150.271892  133.731370  119.069843   \n",
            "10  2015  112.488134  158.120096  152.363846  135.557786  119.841226   \n",
            "11  2016  114.620605  158.552261  152.984348  139.333111  122.108716   \n",
            "12  2017  115.859394  160.943930  155.678440  145.556664  122.791587   \n",
            "13  2018  117.556712  161.097538  156.844507  151.117678  121.976010   \n",
            "14  2019  121.255292  162.177654  158.468892  154.815833  119.027346   \n",
            "15  2020  144.846846  165.595246  160.427162  159.757128  118.475624   \n",
            "16  2021  129.236147  165.289706  160.819795  163.959909  114.176010   \n",
            "17  2022  128.579658  165.252495  161.880640  163.712458  112.735120   \n",
            "\n",
            "          OECD         USA  \n",
            "0   136.650669  151.235271  \n",
            "1   138.655239  152.667177  \n",
            "2   140.670444  154.811003  \n",
            "3   141.063166  156.793736  \n",
            "4   140.273449  161.804881  \n",
            "5   143.532635  166.081175  \n",
            "6   144.829354  166.144788  \n",
            "7   145.488267  166.772010  \n",
            "8   147.041191  167.481497  \n",
            "9   148.245382  168.111097  \n",
            "10  149.932186  169.047471  \n",
            "11  150.904480  169.559622  \n",
            "12  153.238243  171.078160  \n",
            "13  154.743262  173.006902  \n",
            "14  156.448175  175.102267  \n",
            "15  162.309470  181.068735  \n",
            "16  161.120351  183.224832  \n",
            "17  159.554006  178.361187  \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.frame.DataFrame</b><br/>def __init__(data=None, index: Axes | None=None, columns: Axes | None=None, dtype: Dtype | None=None, copy: bool | None=None) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py</a>Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
              "\n",
              "Data structure also contains labeled axes (rows and columns).\n",
              "Arithmetic operations align on both row and column labels. Can be\n",
              "thought of as a dict-like container for Series objects. The primary\n",
              "pandas data structure.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
              "    Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n",
              "    data is a dict, column order follows insertion-order. If a dict contains Series\n",
              "    which have an index defined, it is aligned by its index. This alignment also\n",
              "    occurs if data is a Series or a DataFrame itself. Alignment is done on\n",
              "    Series/DataFrame inputs.\n",
              "\n",
              "    If data is a list of dicts, column order follows insertion-order.\n",
              "\n",
              "index : Index or array-like\n",
              "    Index to use for resulting frame. Will default to RangeIndex if\n",
              "    no indexing information part of input data and no index provided.\n",
              "columns : Index or array-like\n",
              "    Column labels to use for resulting frame when data does not have them,\n",
              "    defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n",
              "    will perform column selection instead.\n",
              "dtype : dtype, default None\n",
              "    Data type to force. Only a single dtype is allowed. If None, infer.\n",
              "copy : bool or None, default None\n",
              "    Copy data from inputs.\n",
              "    For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n",
              "    or 2d ndarray input, the default of None behaves like ``copy=False``.\n",
              "    If data is a dict containing one or more Series (possibly of different dtypes),\n",
              "    ``copy=False`` will ensure that these inputs are not copied.\n",
              "\n",
              "    .. versionchanged:: 1.3.0\n",
              "\n",
              "See Also\n",
              "--------\n",
              "DataFrame.from_records : Constructor from tuples, also record arrays.\n",
              "DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n",
              "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
              "read_table : Read general delimited file into DataFrame.\n",
              "read_clipboard : Read text from clipboard into DataFrame.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "Please reference the :ref:`User Guide &lt;basics.dataframe&gt;` for more information.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Constructing DataFrame from a dictionary.\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [1, 2], &#x27;col2&#x27;: [3, 4]}\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d)\n",
              "&gt;&gt;&gt; df\n",
              "   col1  col2\n",
              "0     1     3\n",
              "1     2     4\n",
              "\n",
              "Notice that the inferred dtype is int64.\n",
              "\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int64\n",
              "col2    int64\n",
              "dtype: object\n",
              "\n",
              "To enforce a single dtype:\n",
              "\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d, dtype=np.int8)\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int8\n",
              "col2    int8\n",
              "dtype: object\n",
              "\n",
              "Constructing DataFrame from a dictionary including Series:\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [0, 1, 2, 3], &#x27;col2&#x27;: pd.Series([2, 3], index=[2, 3])}\n",
              "&gt;&gt;&gt; pd.DataFrame(data=d, index=[0, 1, 2, 3])\n",
              "   col1  col2\n",
              "0     0   NaN\n",
              "1     1   NaN\n",
              "2     2   2.0\n",
              "3     3   3.0\n",
              "\n",
              "Constructing DataFrame from numpy ndarray:\n",
              "\n",
              "&gt;&gt;&gt; df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
              "...                    columns=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; df2\n",
              "   a  b  c\n",
              "0  1  2  3\n",
              "1  4  5  6\n",
              "2  7  8  9\n",
              "\n",
              "Constructing DataFrame from a numpy ndarray that has labeled columns:\n",
              "\n",
              "&gt;&gt;&gt; data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n",
              "...                 dtype=[(&quot;a&quot;, &quot;i4&quot;), (&quot;b&quot;, &quot;i4&quot;), (&quot;c&quot;, &quot;i4&quot;)])\n",
              "&gt;&gt;&gt; df3 = pd.DataFrame(data, columns=[&#x27;c&#x27;, &#x27;a&#x27;])\n",
              "...\n",
              "&gt;&gt;&gt; df3\n",
              "   c  a\n",
              "0  3  1\n",
              "1  6  4\n",
              "2  9  7\n",
              "\n",
              "Constructing DataFrame from dataclass:\n",
              "\n",
              "&gt;&gt;&gt; from dataclasses import make_dataclass\n",
              "&gt;&gt;&gt; Point = make_dataclass(&quot;Point&quot;, [(&quot;x&quot;, int), (&quot;y&quot;, int)])\n",
              "&gt;&gt;&gt; pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n",
              "   x  y\n",
              "0  0  0\n",
              "1  0  3\n",
              "2  2  3\n",
              "\n",
              "Constructing DataFrame from Series/DataFrame:\n",
              "\n",
              "&gt;&gt;&gt; ser = pd.Series([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=ser, index=[&quot;a&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df\n",
              "   0\n",
              "a  1\n",
              "c  3\n",
              "\n",
              "&gt;&gt;&gt; df1 = pd.DataFrame([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], columns=[&quot;x&quot;])\n",
              "&gt;&gt;&gt; df2 = pd.DataFrame(data=df1, index=[&quot;a&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df2\n",
              "   x\n",
              "a  1\n",
              "c  3</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 509);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ejemplo: Crear un DataFrame desde un archivo Excel\n",
        "#df_excel = pd.read_excel('Productividad.csv')\n",
        "\n",
        "# Ejemplo: Crear un DataFrame desde un archivo JSON\n",
        "#df_json = pd.read_json('archivo.json')\n",
        "\n",
        "# Ejemplo: Crear un DataFrame desde un archivo TXT (archivo delimitado por comas o tabulaciones)\n",
        "df_txt = pd.read_csv('/Productividad.csv')\n",
        "print(df_txt)\n",
        "type(df_txt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0V4nf6rceVu"
      },
      "outputs": [],
      "source": [
        "# Ejemplo: Crear un DataFrame desde una consulta SQL\n",
        "#import sqlite3\n",
        "#conn = sqlite3.connect('database.db')\n",
        "#df_sql = pd.read_sql_query(\"SELECT * FROM tabla\", conn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "lcga4WMlcieZ",
        "outputId": "dfe06c30-2bdb-4333-b890-50d71c3501d3"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-27efe70c3e15>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Información guardada en un dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0;31m# open URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    387\u001b[0m                 \u001b[0;31m# Override compression based on Content-Encoding header\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                 \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"method\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m             \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m         return IOArgs(\n\u001b[1;32m    391\u001b[0m             \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0mIncompleteRead\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdetect\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \"\"\"\n\u001b[0;32m--> 631\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Ejemplo: Crear un DataFrame desde una consulta web (no es webscrapping)\n",
        "import pandas as pd\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "# URL donde esta el archivo CSV\n",
        "url = 'https://www.inegi.org.mx/contenidos/programas/enoe/datosabiertos/enoe.zip'\n",
        "zip_filename = '/content/file.zip'\n",
        "\n",
        "# Bajar el archivo a la sesion de colab\n",
        "response = requests.get(url)\n",
        "with open(zip_filename, 'wb') as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "    # Extract all the contents into the /content directory\n",
        "    zip_ref.extractall('/content')\n",
        "\n",
        "# Información guardada en un dataframe\n",
        "data =  pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKpVNTLuc7fK"
      },
      "source": [
        "##3.2. Acceder a elementos específicos en un DataFrame\n",
        "Un DataFrame es como una tabla, y podemos acceder a sus filas, columnas o celdas de forma específica.\n",
        "\n",
        "**Aplicación en Data Science**: Acceder a elementos específicos en un DataFrame permite examinar detalles de los datos o realizar transformaciones en partes concretas del conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idhx_MovdabC",
        "outputId": "25a314df-3524-44a1-d06c-72cd7f2b1884"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columna 'Nombre':\n",
            " 0      Ana\n",
            "1     Luis\n",
            "2    Pedro\n",
            "Name: Nombre, dtype: object\n",
            "Fila con índice 1:\n",
            " Nombre         Luis\n",
            "Edad             30\n",
            "Ciudad    Barcelona\n",
            "Name: 1, dtype: object\n",
            "Celda en fila 0, columna 'Ciudad': Madrid\n"
          ]
        }
      ],
      "source": [
        "# Creamos un DataFrame simple para los ejemplos\n",
        "datos = {'Nombre': ['Ana', 'Luis', 'Pedro'],\n",
        "         'Edad': [23, 30, 25],\n",
        "         'Ciudad': ['Madrid', 'Barcelona', 'Sevilla']}\n",
        "\n",
        "df = pd.DataFrame(datos)\n",
        "\n",
        "# Acceder a una columna\n",
        "print(\"Columna 'Nombre':\\n\", df['Nombre'])\n",
        "\n",
        "# Acceder a una fila por su índice\n",
        "print(\"Fila con índice 1:\\n\", df.iloc[1])\n",
        "\n",
        "# Acceder a una celda específica (fila 0, columna 'Ciudad')\n",
        "print(\"Celda en fila 0, columna 'Ciudad':\", df.at[0, 'Ciudad'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc2lXsGvdfMU"
      },
      "source": [
        "##3.3. Tomar secciones de un DataFrame para crear listas y diccionarios\n",
        "A menudo, en Data Science, necesitamos extraer subconjuntos de datos para realizar análisis específicos o convertirlos en otros formatos.\n",
        "\n",
        "**Aplicación en Data Science:** Extraer listas o diccionarios de un DataFrame nos permite manipular o analizar partes específicas de los datos de manera más flexible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iic2PjvcdoJQ",
        "outputId": "55b04bce-b986-45d4-b4ff-a8c6b6f4da2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columna 'Nombre' como lista: ['Ana', 'Luis', 'Pedro']\n",
            "Fila 1 como diccionario: {'Nombre': 'Luis', 'Edad': 30, 'Ciudad': 'Barcelona'}\n"
          ]
        }
      ],
      "source": [
        "# Extraer una columna como lista\n",
        "nombres = df['Nombre'].tolist()\n",
        "print(\"Columna 'Nombre' como lista:\", nombres)\n",
        "\n",
        "# Extraer una fila como diccionario\n",
        "fila_como_diccionario = df.iloc[1].to_dict()\n",
        "print(\"Fila 1 como diccionario:\", fila_como_diccionario)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utN2oy9D9S_K"
      },
      "source": [
        "## 4. Entendimiento de los datos en matrices\n",
        "Aquí aprenderemos a obtener información básica sobre nuestros datos:\n",
        "- Usaremos `info()` para conocer la estructura de nuestra DataFrame\n",
        "- Usaremos `describe()` para obtener estadísticas descriptivas\n",
        "- Verificaremos si hay valores nulos en nuestro DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSDCenKZ9S_K",
        "outputId": "6662191c-b0df-4dae-9dc1-5ddfc279b4e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3 entries, 0 to 2\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Nombre  3 non-null      object\n",
            " 1   Edad    3 non-null      int64 \n",
            " 2   Ciudad  3 non-null      object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 200.0+ bytes\n",
            "None\n",
            "       Nombre       Edad  Ciudad\n",
            "count       3   3.000000       3\n",
            "unique      3        NaN       3\n",
            "top       Ana        NaN  Madrid\n",
            "freq        1        NaN       1\n",
            "mean      NaN  26.000000     NaN\n",
            "std       NaN   3.605551     NaN\n",
            "min       NaN  23.000000     NaN\n",
            "25%       NaN  24.000000     NaN\n",
            "50%       NaN  25.000000     NaN\n",
            "75%       NaN  27.500000     NaN\n",
            "max       NaN  30.000000     NaN\n",
            "Nombre    0\n",
            "Edad      0\n",
            "Ciudad    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# 4. Entendimiento de los datos en matrices\n",
        "print(df.info())\n",
        "print(df.describe(include='all'))\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5an-H6Ek9S_L"
      },
      "source": [
        "## 5. Limpieza de datos\n",
        "En esta sección, aprenderemos a manejar valores faltantes:\n",
        "- Crearemos un DataFrame con valores nulos\n",
        "- Usaremos `fillna()` para reemplazar los valores nulos con la media de cada columna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i8i9ARy9S_L",
        "outputId": "2dae1337-d4f5-4bc0-a480-deac42d6b054"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     A    B    C\n",
            "0  1.0  4.0  8.5\n",
            "1  2.0  5.0  8.0\n",
            "2  1.5  6.0  9.0\n"
          ]
        }
      ],
      "source": [
        "# 5. Limpieza de datos\n",
        "import numpy as np\n",
        "df_con_nulos = pd.DataFrame({'A': [1, 2, np.nan], 'B': [4, np.nan, 6], 'C': [np.nan, 8, 9]})\n",
        "df_con_nulos.fillna(df_con_nulos.mean(), inplace=True)\n",
        "print(df_con_nulos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5yX8KIZ9S_L"
      },
      "source": [
        "## 6. Escalado de características\n",
        "Aquí aprenderemos a escalar nuestros datos:\n",
        "- Usaremos MinMaxScaler para transformar nuestros datos\n",
        "- Veremos cómo los datos se escalan al rango [0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3W-WGf29S_L",
        "outputId": "925ee379-3f92-407c-a2b7-c4e7564a73d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datos originales:\n",
            " [[1 2]\n",
            " [2 4]\n",
            " [3 6]\n",
            " [4 8]]\n",
            "Datos escalados:\n",
            " [[0.         0.        ]\n",
            " [0.33333333 0.33333333]\n",
            " [0.66666667 0.66666667]\n",
            " [1.         1.        ]]\n"
          ]
        }
      ],
      "source": [
        "# 6. Escalado de características\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "datos = np.array([[1, 2], [2, 4], [3, 6], [4, 8]])\n",
        "scaler = MinMaxScaler()\n",
        "datos_escalados = scaler.fit_transform(datos)\n",
        "print(\"Datos originales:\\n\", datos)\n",
        "print(\"Datos escalados:\\n\", datos_escalados)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYE1kZHY9S_L"
      },
      "source": [
        "## 7. Codificación de variables categóricas\n",
        "En esta sección, aprenderemos a manejar datos categóricos:\n",
        "- Crearemos un DataFrame con variables categóricas\n",
        "- Usaremos `get_dummies()` para convertir estas variables en formato numérico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eli4xN69S_L",
        "outputId": "f8e4201c-d459-46a8-aeca-c65f5fc040d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Color   Tamaño\n",
            "0   Rojo   Grande\n",
            "1  Verde  Pequeño\n",
            "2   Azul  Mediano\n",
            "   Color_Azul  Color_Rojo  Color_Verde  Tamaño_Grande  Tamaño_Mediano  \\\n",
            "0       False        True        False           True           False   \n",
            "1       False       False         True          False           False   \n",
            "2        True       False        False          False            True   \n",
            "\n",
            "   Tamaño_Pequeño  \n",
            "0           False  \n",
            "1            True  \n",
            "2           False  \n"
          ]
        }
      ],
      "source": [
        "# 7. Codificación de variables categóricas\n",
        "df_categorico = pd.DataFrame({'Color': ['Rojo', 'Verde', 'Azul'], 'Tamaño': ['Grande', 'Pequeño', 'Mediano']})\n",
        "print(df_categorico)\n",
        "df_codificado = pd.get_dummies(df_categorico)\n",
        "print(df_codificado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LvHXSt09S_L"
      },
      "source": [
        "## 8. División de datos\n",
        "Aquí aprenderemos a dividir nuestros datos en conjuntos de entrenamiento y prueba:\n",
        "- Usaremos `train_test_split` para dividir nuestros datos\n",
        "- Veremos cómo se separan los datos en características (X) y etiquetas (y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IS7vMBT9S_M",
        "outputId": "5a9c60ea-35dc-4d8b-c9e9-47093f93012c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datos de entrenamiento:\n",
            " [[4 8]\n",
            " [1 2]\n",
            " [3 6]]\n",
            "Datos de prueba:\n",
            " [[2 4]]\n"
          ]
        }
      ],
      "source": [
        "# 8. División de datos\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = np.array([[1, 2], [2, 4], [3, 6], [4, 8]])\n",
        "y = np.array([0, 1, 0, 1])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(\"Datos de entrenamiento:\\n\", X_train)\n",
        "print(\"Datos de prueba:\\n\", X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aSz2E089S_M"
      },
      "source": [
        "## 9. Estructuras de control\n",
        "En esta sección, aprenderemos sobre estructuras de control básicas en Python:\n",
        "- Usaremos una declaración `if-else` para tomar decisiones basadas en condiciones\n",
        "- Utilizaremos un bucle `for` para repetir acciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI3TARXm9S_M",
        "outputId": "5fd4459c-d3f9-4a3f-b2ee-5ca615fb2ecd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.99 es menor o igual que 5\n",
            "Iteración: 0\n",
            "Iteración: 1\n",
            "Iteración: 2\n",
            "Iteración: 3\n",
            "Iteración: 4\n"
          ]
        }
      ],
      "source": [
        "# 9. Estructuras de control\n",
        "x = 4.99\n",
        "if x > 5:\n",
        "    print(f\"{x} es mayor que 5\")\n",
        "else:\n",
        "    print(f\"{x} es menor o igual que 5\")\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"Iteración: {i}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLbnCU-g9S_M"
      },
      "source": [
        "## 10. Funciones\n",
        "Finalmente, aprenderemos sobre funciones en Python:\n",
        "- Definiremos una función simple que suma dos números\n",
        "- Llamaremos a la función y imprimiremos el resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ogd_bG479S_M",
        "outputId": "673c2176-8fe9-47cd-fe59-60529959ea13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La suma es: 15\n"
          ]
        }
      ],
      "source": [
        "# 10. Funciones\n",
        "def sumar(a, b):\n",
        "    return a + b\n",
        "resultado = sumar(10, 5)\n",
        "print(\"La suma es:\", resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB6O-5dXem2e"
      },
      "source": [
        "##11.1. Convertir Texto, Audio e Imágenes a DataFrames para Modelos de Machine Learning\n",
        "En esta sección, aprenderemos cómo convertir diferentes tipos de datos, como texto, audio e imágenes, en un formato que pueda ser utilizado por modelos de machine learning. Utilizaremos pandas para trabajar con DataFrames, así como bibliotecas adicionales según sea necesario para procesar cada tipo de dato.\n",
        "\n",
        "**En esta lección, aprendemos**:\n",
        "\n",
        "- Cómo convertir texto a DataFrames utilizando técnicas de vectorización.\n",
        "- Cómo convertir audio a DataFrames extrayendo características.\n",
        "- Cómo convertir imágenes a DataFrames utilizando la representación de píxeles.\n",
        "\n",
        "Estos pasos son esenciales para preparar datos no estructurados para su uso en modelos de machine learning. ¡Sigue explorando y experimentando con diferentes tipos de datos!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgMNIV7ifLbC"
      },
      "source": [
        "##11.1. Convertir Texto a DataFrames\n",
        "El texto puede ser procesado y convertido en un DataFrame para su uso en modelos de machine learning. Para ello, utilizaremos técnicas como la tokenización y la creación de características.\n",
        "\n",
        "**Aplicación en Data Science:** La conversión de texto a un formato numérico permite que los modelos de machine learning comprendan el contenido textual y realicen tareas como clasificación o análisis de sentimientos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnjA5yUQd6kL",
        "outputId": "547a7b30-78e4-4bd9-88b3-f626ac2f4a38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame de texto vectorizado:\n",
            "    aprendizaje  automático  ciencia  combina  datos  de  el  es  estadística  \\\n",
            "0            1           1        0        0      0   0   1   1            0   \n",
            "1            0           0        0        0      0   1   0   0            0   \n",
            "2            0           0        1        1      1   1   0   0            1   \n",
            "\n",
            "   fascinante  la  learning  los  machine  modelos  poderosos  programación  \\\n",
            "0           1   0         0    0        0        0          0             0   \n",
            "1           0   0         1    1        1        1          1             0   \n",
            "2           0   1         0    0        0        0          0             1   \n",
            "\n",
            "   son  \n",
            "0    0  \n",
            "1    1  \n",
            "2    0  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Ejemplo de datos de texto\n",
        "documentos = [\n",
        "    \"El aprendizaje automático es fascinante.\",\n",
        "    \"Los modelos de machine learning son poderosos.\",\n",
        "    \"La ciencia de datos combina estadística y programación.\"\n",
        "]\n",
        "\n",
        "# Convertir el texto en un DataFrame\n",
        "df_texto = pd.DataFrame(documentos, columns=['Texto'])\n",
        "\n",
        "# Vectorización: convertir texto a vectores numéricos\n",
        "vectorizer = CountVectorizer()\n",
        "X_texto = vectorizer.fit_transform(df_texto['Texto']).toarray()\n",
        "\n",
        "# Crear un nuevo DataFrame con las características\n",
        "df_vectorizado_texto = pd.DataFrame(X_texto, columns=vectorizer.get_feature_names_out())\n",
        "print(\"DataFrame de texto vectorizado:\\n\", df_vectorizado_texto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSvaGka8fYyF"
      },
      "source": [
        "##11.2. Convertir Audio a DataFrames\n",
        "El audio también puede ser convertido a un formato adecuado para machine learning. Normalmente, esto implica extraer características del audio, como espectrogramas o MFCC (coeficientes cepstrales en las frecuencias Mel).\n",
        "\n",
        "**Aplicación en Data Science**: Al convertir audio en características, podemos entrenar modelos para tareas como reconocimiento de voz o clasificación de sonidos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEr8ZkYCfdMZ",
        "outputId": "1a7e0259-4dea-41b7-aac8-24d1db4bce8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame de características de audio:\n",
            "      MFCC_1    MFCC_2    MFCC_3    MFCC_4    MFCC_5    MFCC_6    MFCC_7  \\\n",
            "0  0.441599  0.802052  0.866199  0.264139  0.086676  0.412221  0.431434   \n",
            "1  0.632802  0.485790  0.649118  0.958909  0.810847  0.642078  0.049967   \n",
            "2  0.751675  0.843779  0.870630  0.258675  0.367389  0.995523  0.675483   \n",
            "3  0.055854  0.637960  0.723058  0.517526  0.074149  0.135113  0.004027   \n",
            "4  0.151325  0.435007  0.776324  0.554546  0.845341  0.224051  0.748653   \n",
            "\n",
            "     MFCC_8    MFCC_9   MFCC_10   MFCC_11   MFCC_12   MFCC_13  \n",
            "0  0.672691  0.413058  0.300433  0.488690  0.045054  0.160449  \n",
            "1  0.830797  0.526211  0.743074  0.763848  0.917990  0.528824  \n",
            "2  0.233135  0.400254  0.374289  0.532985  0.342411  0.512792  \n",
            "3  0.389388  0.544879  0.489665  0.432596  0.027781  0.162355  \n",
            "4  0.600320  0.628686  0.751578  0.004200  0.227740  0.178368  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "# Cargar un archivo de audio y extraer características\n",
        "# audio_path = 'archivo_audio.wav'\n",
        "# y, sr = librosa.load(audio_path, sr=None)\n",
        "\n",
        "# Para este ejemplo, generamos un array de características ficticias\n",
        "# características = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "# características = características.T  # Transponer para que cada fila sea una observación\n",
        "\n",
        "# Ejemplo de características ficticias (por ejemplo, 5 muestras de 13 coeficientes)\n",
        "caracteristicas = np.random.rand(5, 13)  # Simulación de 5 muestras de características\n",
        "\n",
        "# Crear un DataFrame con las características de audio\n",
        "df_audio = pd.DataFrame(caracteristicas, columns=[f'MFCC_{i+1}' for i in range(caracteristicas.shape[1])])\n",
        "print(\"DataFrame de características de audio:\\n\", df_audio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-vOSnNFfntF"
      },
      "source": [
        "##11.3. Convertir Imágenes a DataFrames\n",
        "Las imágenes se pueden convertir en DataFrames extrayendo características, como los píxeles o utilizando técnicas de extracción de características como SIFT o HOG.\n",
        "\n",
        "**Aplicación en Data Science**: La conversión de imágenes a un formato tabular permite que los modelos de machine learning puedan realizar tareas como clasificación de imágenes, detección de objetos o segmentación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN2iJKo3fv_4",
        "outputId": "9d2ba02e-6aef-4262-a8b3-d3ca76ac9d33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame de píxeles de la imagen:\n",
            "       Rojo  Verde  Azul\n",
            "0      174    201   231\n",
            "1      174    202   232\n",
            "2      174    203   232\n",
            "3      177    204   234\n",
            "4      177    204   234\n",
            "...    ...    ...   ...\n",
            "9995     3      7     3\n",
            "9996     4      6     2\n",
            "9997     4      6     1\n",
            "9998     5      6     3\n",
            "9999    16     18    13\n",
            "\n",
            "[10000 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_sample_image\n",
        "import numpy as np\n",
        "\n",
        "# Cargar una imagen de muestra\n",
        "china = load_sample_image(\"china.jpg\")\n",
        "\n",
        "# Redimensionar la imagen usando Pillow (PIL) en lugar de NumPy\n",
        "from PIL import Image\n",
        "china_resized = np.array(Image.fromarray(china).resize((100, 100)))\n",
        "\n",
        "# Aplanar la imagen en un array\n",
        "pixels = china_resized.reshape(-1, 3)  # Convertir a un array 2D\n",
        "\n",
        "# Crear un DataFrame a partir de los píxeles de la imagen\n",
        "df_imagen = pd.DataFrame(pixels, columns=['Rojo', 'Verde', 'Azul'])\n",
        "print(\"DataFrame de píxeles de la imagen:\\n\", df_imagen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xyAChRZfhy0"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1v3jfmGUfTq6"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
